<h2>1. Abstract</h2>
This paper aims to provide a comprehensive review of the deep learning-based techniques used in the field of video anomaly detection. Specifically, deep learning-based approaches have been categorized into different methods by their objectives and learning metrics. Additionally, preprocessing and feature engineering techniques are discussed thoroughly for the vision-based domain. This paper also describes the benchmark databases used in training and detecting abnormal human behavior. Finally, the common challenges in video surveillance are discussed.
<h2>2. Introduction</h2>
Focus on the understanding of abnormal human behaviors, since the identification and recognition of actions is key for an intelligent video system.
<h2>3. Background knowledge and related works</h2>
Video surveillance includes the implementation of knowledge of feature extraction, scene understanding, object tracking, object identification and model generation. Traditional machine learning algorithms in AbHAR based on learning shallow features from video data: random forest, bayesian networks, markov models and SVM. Four main steps of AbHAR: object segmentation, object classification, object tracking and action recognition.
<h2>4. Benchmark databases</h2>
<h3>4.1 CASIA action database</h3>
CASIA action database is a type of RGB single-scene dataset. This database includes human outdoor activities captured from different viewing angles. There are eight types of action for a single person, such as walk, run, bend, jump, crouch, faint, wander and punching a car from 24 different subjects. There are also seven types of two person interaction such as rob, fight, follow, follow and gather, meet and part, meet and gather, overtake. The database includes two main parts: single person actions and interactions.
<h3>4.2 Subway database</h3>
Subway database is also a type of single-scene database. This database comprises two long video recordings monitoring people at a subway entrance and exit. There is no spatial ground truth available. The video was recorded in grayscale format at 15 FPS with a resolution of 512 $\times$ 384 and it has 125475 frames in total. The anomalous events are mainly wrong directions, loitering, no payment, people jumping or squeezing through turnstiles and a janitor cleaning the walls.
<h3>4.3 UMN crowd abnormality database</h3>
UMN database is a multiscene database. It has a total of 11 short videos, which are aggregated into one long video of 4 min 17 s with 7739 frames. The small videos begin with normal behavior, then change to abnormal. There is one scenario for indoor scene and two outdoors. All the videos have the same frame rate of 30 FPS and were recorded at a resolution of 640 $\times$ 480 using a static camera. The ground truth is a temporal annotation.
<h3>4.4 Anomalous behavior database</h3>
Anomalous behavior database comprises eight videos recorded in various challenging conditions such as illumination effects, scene clutter, variable target appearance, rapid motion and camera jitter. The database was also provided with a spatiotemporal ground truth, along with software for detecting abnormal events in certain parts of each video. The image sequences in this database mainly focus on the activities of humans and vehicles in certain public locations such as airport, river, sea and on a train.
<h3>4.5 Avenue database</h3>
It contains 37 videos, divided into 16 normal videos for training and 21 abnormal videos for testing. The database is of a RGB single-scene type. There is a total of 47 abnormal events, categorized into three main subjects: strange actions, wrong direction and abnormal object. These videos were captured at CUHK campus avenue with 30652 frames (15328 training, 15324 testing) in total. Each image sequence has a resolution of 640 $\times$ 360 and frame rate of 25 FPS. The author provided both temporal and spatial annotations. 
<h3>4.6 UCSD anomaly detection database</h3>
It includes two subdatasets: Ped1 and Ped2. Both include a grayscale sequence of images recorded at 10 FPS with a resolution of 238 $\times$ 158 for Ped1 and 360 $\times$ 240 for Ped2. Each dataset is a single-scene dataset. Both have training videos containing only normal behaviors and testing videos containing abnormal events. Ped1 dataset includes 34 normal training videos and 36 abnormal testing videos of groups of people walking towards and away from camera. These abnormal cases are mainly related to abnormal vehicles such as bicycles and cars entering the crowd. Ped2 dataset contains 16 training videos and 12 testing videos with 12 abnormal events. Ped2 includes scenes with pedestrian movement parallel to the camera plane.
<h3>4.7 ShanghaiTech campus database</h3>
It contains 330 training videos with only normal events, and 107 testing videos with 130 abnormal events. The total frames are 317398 with 17090 irregularity frames. The database was acquired using an RGB camera with a resolution of 856 $\times$ 480 at 24 FPS, overlooking pedestrian walkways. It consists of 13 scenes with complex light conditions, camera angles and various anomaly types, mainly related to strange objects, wrong direction and strange actions. 
<h3>4.8 UCF-Crime database</h3>
UCF-Crime is a compilation of 128 h of 1900 internet videos, taken from many RGB cameras at different locations. The anomalous events includes abuse, arrest, arson, assault, road accident, burglary, explosion, fighting, robbery, shooting, stealing, shoplifting and vandalism. These videos cover 13 real-world situations and can be used for two primary tasks: the event recognition of 13 group activities and anomaly detection in each specific group. The authors only provided temporal annotations. 
<h3>4.9 Street scene database</h3>
Street scene is a RGB single-scene type. There are a total of 203257 image sequences, extracted from original videos at a frame rate of 15 FPS. The database consists of 205 anomalous events, such as jaywalking, biker outside lane and loitering... recorded at a resolution of 1280 $\times$ 720.
<h2>5. Preprocessing data for video anomaly detection</h2>
<h3>5.1 Segmentation</h3>
Segmentation includes background construction and foreground extraction techniques. Many of methods proposed for video anomaly detection have tried to exploit both background and foreground information.
<h3>5.2 Feature extraction and selection</h3>
Local representative features, global representative features and semantic features.
<h2>6. Deep learning methods</h2>
<h3>6.1 reconstruction-based method</h3>
Let $x$ be the input image sequences and $f$ be the neural network that reconstructs $x$. The reconstruction cost function $\Theta$ can be defined as a function to compute error $e$ between original input $x$ and $f(x)$: $e = \Theta(x, f(x))$. A popular neural network used for reconstruction error function $\Theta$ is an autoencoder network. The approach using an autoencoder is based on the assumption that a network will return a high reconstruction error score for an abnormal instance. However, this assumption does not necessarily hold true, in some cases, autoencoders can generalize the abnormal instance as well as the normal instance. This means the reconstruction error score is lower than expected.
<h3>6.2 Multiclass classifier method</h3>
Different approaches have framed the anomaly detection problem as a multiclass classification. This classification method receives video segment as an input $x$ and returns an output $y$ indicating a class label in redefined categories: $y = f(x), y \in \mathbb{R}$.
<h3>6.3 Future frame prediction method</h3>
One problem with reconstruction-based methods is that autoencoder can accidentally reconstruct abnormal instances as well as normal ones. Given $x_t$ is the input video segment at time step $t$, the future frame prediction method provides a function $p$ to predict the next segment frames at time $t$ + 1 and compare error cost between predicted frames and current frames at that time. If the error value is greater than a defined threshold value, then the frames are tagged as abnormal instances: $x_{t + 1} = p(x_t)$. GANs is usually used for this approach. Some previous works on reconstruction-based methods also took advantage of this future frame prediction approach.
<h3>6.4 Scoring method</h3>
In scoring method, the network tries to predict anomaly score for each video segment. Thus, it can be considered a regression problem where the purpose is to assign a high score value for any abnormal instance. The scoring method uses a function $s$ to take input video segments $x$ and assign a $t$ value indicating the anomaly score in each segment: $t = s(x), t \in \mathbb{R}$.
<h3>6.5 Anomaly score</h3>
The difference between predicted frame/reconstructed frame $\hat{I}$ and ground truth frame $I$ is computed using PSNR: PSNR($I, \hat{I}$) = 10$\log_{10}\frac{[max_{\hat{I}}]^2}{\frac{1}{N}\sum_{i = 1}^N(I_i - \hat{I}_i)^2}$. The PSNR scores of all frames in a video are normalized to range [0, 1]. Then, the anomaly score is obtained using following formula: $S(t) = \frac{\mathrm{PSNR}_t - min(\mathrm{PSNR})}{max(\mathrm{PSNR}) - min(\mathrm{PSNR})}$.
<h2>7. Research gaps, challenges and future research</h2>
<h3>7.1 Research gaps</h3>
Recent methods have focused on exploiting both appearance and motion information in video by extracting structural features and optical flow $\rightarrow$ high computational cost. Therefore, some proposed methods have tried to capture motion information without using optical flow. On the other hand, most recently proposed methods have tried to improve accuracy of anomaly detection systems by applying a modern model.
<h3>7.2 Challenges</h3>
Overall, researchers have relied on supervised learning methods for their approach. These problems can be solved by utilizing transfer learning techniques or crowd-sourcing. In addition, there is a need for standard metrics that allow a fair comparison between different approaches. During inference, there are also some limitations in most approaches, such as false alarms due to subtle details in human motion and appearance. In some cases, early detection is also necessary for crime prevention. These challenges can be approached by choosing representative features for AbHAR that allow surveillance system to learn and simulate human behaviors. A noisy environment is considered the main issue in many surveillance systems. A cluttered and dynamic background is challenging to model accurately. In addition, occlusion, low illumination, low-quality videos and various viewpoints also occur in real-time surveillance. Multimodal data can overcome these challenges.
<h3>7.3 Future research</h3>
Future research will focus on using transfer learning methods to explore spatiotemporal relationships in video segments. Moreover, extracting rich semantic features from multimodal datasets is a research trend since this information enables explaining the long-term relationship between interacting objects. Lastly, the physical interactions between humans or humans-objects require more investigation.