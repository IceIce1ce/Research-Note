<h2>1. Abstract</h2>
First design a multi-head classification module (each head serves as a classifier) with a diversity loss to maximize the distribution differences of predicted pseudo labels across heads. Then devise an iterative uncertainty pseudo label refinement strategy, which improves not only the initial pseudo labels but also the updated ones obtained by the desired classifier in the second stage.
<h2>2. Method</h2>
<h3>2.1 Completeness of pseudo labels</h3>
Each head $f_g(\cdot; \phi^k)$ is composed of three fully connected layers. Taking the video segment features $\mathcal{X}_i = \{x_{i, s}\}^S_{s = 1}$ as input, each head outputs the anomaly scores of each segment, which are further passed through a softmax to generate a score distribution: $\hat{y}^k_i = softmax(f_g(\mathcal{X}_i; \phi^k))$, where $\hat{y}^k_i \in \mathbb{R}^{S \times 1}$ denotes score distribution of $i$-th video from $k$-th head. . The predicted score distributions of $K$ heads minimizes: $\mathcal{L}_{diver} = \frac{1}{Z}\sum_{k = 1}^{K - 1}\sum_{q = k + 1}^K\frac{\hat{y}^k_i \cdot \hat{y}^q_i}{||\hat{y}^k_i||||\hat{y}^q_i||}$, where $Z = \frac{1}{2}K(K - 1)$. . A regularization term on the norm of the segment score sequences is used: $\mathcal{L}_{norm} = \frac{1}{K}\sum_{k = 1}^K|||\mathcal{A}^k|| - ||\mathcal{A}^{avg}|||$, where $\mathcal{A}^k = f_g(\mathcal{X}_i; \phi^k)$ denotes the anomaly scores generated by $k_{th}$ and $\mathcal{A}^{avg}$ is the average of f the anomaly scores produced by each head $\mathcal{A}^{avg} = \frac{1}{K}\sum_{k = 1}^K(f_g(\mathcal{X}_i; \phi^k))$. Finally, $\mathcal{A}^{avg}$ is followed by a sigmoid to n to obtain the predicted segment-level labels ranging from 0 to 1: $\hat{y}_i = sigmoid(\mathcal{A}^{avg})$. (6) Finally, the completeness enhanced pseudo label generator is trained with loss as follows: $\mathcal{L}_{fg} = \mathcal{L}_{MIL} + \alpha\mathcal{L}_{diver} + \alpha\mathcal{L}_{norm}$.
<h3>2.2 Uncertainty of pseudo labels</h3>
<h4>2.2.1 Uncertainty estimation</h4>
Introduce the uncertainty estimation leveraging Monte Carlo (MC) Dropout [6] so that clips with low uncertainty (i.e., reliable) pseudo labels are selected for training $f_c$. For training video clips $C_i = \{c_{i, t}\}^T_{t = 1}$, in the first iteration, use multi-head classifier in the first stage as the trained model ($f = f_g$). In the remaining iterations, $f = f_c$. Each pass generates clip-level pseudo labels as follows: $\hat{y}^m_i = sigmoid(f(C_i; \overline{W}^m))$, where $\overline{W}^m$ denotes $m^{th}$ sampled masked model parameters and $\hat{y}^m_i = \{\hat{y}^m_{i, t}\}^{T_i}_{t = 1}$. The clip-level pseudo labels used as the supervision for training the clip classifier are given by the predictive mean: $E(\hat{y}_i) = \frac{1}{M}\sum_{m = 1}^M(\hat{y}^m_i)$. The prediction uncertainties $\mathcal{U}_i = \{u_{i, t}\}^{T_i}_{t = 1}$ of $\hat{y}_i$ are given by the diagonal entries in the covariance matrix Cov($\hat{y}_i$) = $\frac{1}{M}\sum_{m = 1}^M\hat{y}^{m^T}_i\hat{y}^m_i - E(\hat{y}_i)^TE(\hat{y}_i)$.
<h4>2.2.2 Iterative reliable clip mining</h4>
To model the temporal relationship between video clips. The clip features of each video are stored in a memory pool. After obtaining the selected reliable clip, retrieve the window size $w$ clip features $\mathcal{H}_{i, t} = [c_{i, t- w},...,c_{i, t - 1}]$ before the current clip $c_{i, t}$ from the memory pool. Obtain $\overline{\mathcal{H}}_{i, t}$ by performing mean pooling on $\mathcal{H}_{i, t}$ and then concatenate the current clip feature $c_{i, t}$ with $\overline{\mathcal{H}}_{i, t}$ into a new temporal clip feature $\overline{c}_{i, t}$. Use all reliable temporal features set $\Omega_R(C)$ and reliable clip-level pseudo labels $\Omega_R(\overline{y})$ to train the clip classifier $f_c$ based on BCE loss.
<h2>3. Datasets</h2>
UCF-Crime, TAD and XD-Violence.
<h2>4. Metrics</h2>
AUC and AP.
<h2>5. Code</h2>
https://github.com/ArielZc/CU-Net.