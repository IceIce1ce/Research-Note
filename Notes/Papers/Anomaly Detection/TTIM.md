<h2>1. Abstract</h2>
Proposes a traffic accident detection method that helps to determine whether each frame shows accidents by generating and considering object trajectories using influence maps and a convolutional neural network (CNN). The influence maps with spatiotemporal relationships were enhanced to improve the detection of traffic accidents. A CNN is utilized to extract latent representations from the influence maps produced by object trajectories.
<h2>2. Proposed method</h2>
<h3>2.1 Overview of traffic accident detection</h3>
The proposed traffic accident detection method comprises two phases: tracking and execution. The tracking phase consists of two parts: a Bounding Box Generator and a Trajectory Extractor. The execution phase consists of two parts: an Influence Map Generator and a Detection Executor. The Influence Map Generator focuses on analyzing the spatiotemporal relationships among the trajectories of 2D objects using influence maps.
<h3>2.2 Influence map generator</h3>
Distances among objects in the influence map notation, the equation for defining the radius of the circle is as follows: $r_c = \sqrt{(w^2_i + h^2_i)}$, where $r_{min} = w_i$ if $(w_i \geq h_i)$ and $h_i$ otherwise, where $r_c$ is the radius of the blue circle; $r_{min}$ is the shorter width and height of the 2D object trajectory; $i$ is the input 2D object trajectory; $w_i$ is width and $h_i$ is height of 2D object trajectory. A higher distance ratio indicates that the overlapping area between two objects is larger, and the blue color would be darker. Furthermore, the color of the blue circle deepened over time as follows: $x = \frac{d_{min}}{(r_c + r_{min})/2} \times 100, c = 4 + \frac{60}{T_{max}} \times T_{now}$, where $x$ is the distance ratio, $d_{min}$ is the distance to the nearest object around the object being measured, $c$ is the degree of color change, $T_{max}$ is the maximum frame in which the trajectory coordinates exist, and $T_{now}$ is the frame in which the current trajectory coordinates are located. Accident discrimination was calculated as follows: $y = 10$ if $(\frac{w_c}{w_i} + \frac{h_c}{h_i}) \times 100 \geq 5$ and 30 otherwise, where $y$ is the area of object bounding box, $w_c, h_c$ are the width and height of the object bounding box. For the object trajectories in the influence map notation, the trajectory coordinates based on the movement of the objects in each frame were drawn with red lines. First, the distance between any two objects was calculated for each 2D object trajectory in the Influence Map Generator, and a blue circle was drawn on the corresponding trajectory coordinate point. The value of accident discrimination was then determined based on each area of the object bounding box, and a green circle was drawn at the corresponding trajectory coordinate point according to the value. Finally, red lines were drawn based on the coordinates of each 2D object trajectory to represent the corrected and smoothened 2D object trajectories.
<h2>3. Datasets</h2>
CADP.
<h2>4. Metrics</h2>
Accuracy.