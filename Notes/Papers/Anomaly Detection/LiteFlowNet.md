<h2>1. Abstract</h2>
Present a more effective flow inference approach at each pyramid level through a lightweight cascaded network. Present a novel flow regularization layer to ameliorate the issue of outliers and vague flow boundaries by using a feature-driven local convolution. Network owns an effective structure for pyramidal feature extraction and embraces feature warping rather than image warping as practiced in FlowNet2.
<h2>2. LiteFlowNet</h2>
LiteFlowNet is composed of two compact sub-networks that are specialized in pyramidal feature extraction and optical flow estimation. NetC transforms any given image pair into two pyramids of multi-scale high-dimensional features. NetE consists of cascaded flow inference and regularization modules that estimate coarse-to-fine flow fields.
<h3>2.1 Pyramidal feature extraction</h3>
NetC is a two-stream network in which the filter weights are shared across the two streams. Each of them functions as a feature descriptor that transforms an image I to a pyramid of multi-scale high-dimensional features $\{\mathcal{F}_k(I)\}$ from the highest spatial resolution ($k = 1$) to the lowest spatial resolution ($k = L$). The pyramidal features are generated by stride-s convolutions with the reduction of spatial resolution by a factor $s$ up the pyramid.
<h3>2.2 Feature warping</h3>
At each pyramid level, a flow field is inferred from high-level features $\mathcal{F}_1$ and $\mathcal{F_2}$ of images $I_1$ and $I_2$. Propose to reduce feature-space distance between $\mathcal{F_1}$ and $\mathcal{F_2}$ by feature warping (f-warp). Specifically, $\mathcal{F_2}$ is warped towards $\mathcal{F_1}$ by f-warp via flow estimate $\overline{x}$ to $\overline{\mathcal{F}}_2(x)$ = $\mathcal{F_2}(x + \overline{x}) \sim \mathcal{F_1}(x)$. To allow end-to-end training, $\mathcal{F}$ is interpolated to $\overline{\mathcal{F}}$ for any sub-pixel displacement $\overline{x}$ as follows: $\overline{\mathcal{F}}(x) = \sum_{x^i_s \in N(x_s)}\mathcal{F}(x^i_s)(1 - |x_s - x^i_s|)(1 - |y_s - y^i_s|)$, where $x_s = x + \overline{x} = (x_s, y_s)^T$ denotes the source coordinates in the input feature map $\mathcal{F}$ that defines the sample point, x = $(x, y)^T$ denotes the target coordinates of regular grid in the interpolated feature map $\overline{\mathcal{F}}$ and $N(x_s)$ denotes the four pixel neighbors of $x_s$. 
<h3>2.3 Cascaded flow inference</h3>
At each pyramid level of NetE, pixel-by-pixel matching of high-level features yields coarse flow estimate. 
- First flow inference (descriptor matching): Point correspondence between $I_1$ and $I_2$ is established through computing correlation of high-level feature vectors in individual pyramidal features $\mathcal{F}_1$ and $\mathcal{F}_2$ as follows: $c(x, d) = \mathcal{F}_1(x) \cdot \mathcal{F}_2(x + d)/N$, where $c$ is the matching cost between point $x$ in $\mathcal{F}_1$ and point $x + d$ in $\mathcal{F}_2, d \in \mathbb{Z}$ is the displacement vector from $x$ and $N$ is the length of the feature vector. A cost volume $C$ is built by aggregating all the matching costs into a 3D grid. In the descriptor matching unit $M$, residual flow $\Delta \overline{x}_m$ is inferred by filtering cost volume $C$. A complete flow field $\overline{x}_m$ is computed as: $\overline{x}_m = M(C(\mathcal{F}_1, \overline{F}_2; d)) + s\overline{x}$.
- Second flow inference (sub-pixel refinement): $\mathcal{F}_2$ is warped to $\mathcal{F}_2$ via flow estimate $\overline{x}_m$. Sub-pixel refinement unit $S$ yields a more accurate flow field $\overline{x}_s$ by minimizing feature-space distance between $\mathcal{F}_1$ and $\overline{\mathcal{F}}_2$ through computing residual flow $\Delta \overline{x}_s$ as: $\overline{x}_s = S(\mathcal{F}_1, \overline{\mathcal{F}}_2, \overline{x}_m) + \overline{x}_m$.
<h3>2.4 Flow regularization</h3>
Propose to use a feature-driven local convolution (f-lcon) to regularize flow field from the cascaded flow inference. A vector-valued feature $F$ that has to be regularized has $C$ channels and a spatial dimension $M \times N$. Define G = {$g$} as the set of filters used in f-lcon layer. The operation of f-lcon to $F$ can be formulated as follow: $f_g(x, y, c) = g(x, y, c) * f(x, y, c)$, where $f(x, y, c) is a $w \times w$ patch centered at position $(x, y)$ of channel $c$ in $F, g(x, y, c)$ is the corresponding $w \times w$  regularization filter, and $f_g(x, y, c)$ is a scalar output for $x = (x, y)^T$ and $c = 1,...,C$. To be specific for regularizing flow field $\overline{x}_s$ from the cascaded flow inference, replace $F$ to $\overline{x}_s$. Flow regularization module $R$ is defined: $\overline{x}_r = R(\overline{x}_s; G)$. Define a feature-driven CNN distance metric $\mathcal{D}$ that estimates local flow variation using pyramidal feature $\mathcal{F}_1$, flow field $\overline{x}_s$ from the cascaded flow inference, and occlusion probability map $O$. In summary, $\mathcal{D}$ is adaptively constructed by a CNN unit $R_D$ as: $\mathcal{D} = R_D(\mathcal{F}_1, \overline{x}_s, O)$. Each filter $g$ of f-1con is constructed as: $g(x, y, c) = \frac{\exp(-\mathcal{D}(x, y, c)^2)}{\sum_{x_i, y_i} \in N(x, y)\exp(-\mathcal{D}(x_i, y_i, c)^2)}$, where $N(x, y)$ denotes the neighborhood containing $\omega \times \omega$ pixels centered at position $(x, y)$. For a $C$-channel input $F$, use $C$ tensors $\overline{G}(1)...\overline{G}(c)$ to store f-1con filter set $G$. Each f-1con filter $g(x, y, c)$ is folded into a $1 \times 1 \times w^2$ 3D column and then packed into the $(x, y)$-entry of a $M \times N \times w^2$ 3D tensor $\overline{G}(c)$. Same folding and packing operations are also applied to each patch in each channel of $F$. This results $C$ tensors $\overline{F}(1)...\overline{F}(C)$ for $F$. $F_g(c) = \overline{G}(c) \odot \overline{F}(c)$, where $F_g(c)$ means the $c$-th $xy$-slice of regularized $C$-channel feature $F_g$.
<h2>3. Datasets</h2>
FlyingChairs, Sintel clean and final, KITTI12, KITTI15 and Middlebury.
<h2>4. Metrics</h2>
F1-all, EPE.
<h2>5. Code</h2>
https://github.com/twhui/LiteFlowNet.