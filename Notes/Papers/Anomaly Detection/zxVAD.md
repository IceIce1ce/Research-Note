<h2>1. Abstract</h2>
Propose a new ‘Zero-shot Cross-domain Video Anomaly Detection (zxVAD)’ framework that includes a future-frame prediction generative model setup. The model uses a novel Normalcy Classifier module to learn the features of normal event videos by learning how such features are different relatively to features in pseudo-abnormal examples. A novel Untrained Convolutional Neural Network based Anomaly Synthesis module crafts these pseudo-abnormal examples by adding foreign objects in normal video frames with no extra training cost. With novel relative normalcy feature learning strategy, zxVAD generalizes and learns to distinguish between normal and abnormal frames in a new target domain without adaptation during inference.
<h2>2. Proposed zxVAD framework</h2>
It consists of an untrained CNN based pseudo-anomaly synthesis module. These pseudo-abnormal frames along with predicted future-frame are utilized in Normalcy Classifier module to regularize the backbone generator to learn relative normalcy features.
<h3>2.1 Notations</h3>
Denote a sample video as $[v_1,...v_{L_v}] \in \mathbb{R}^{L_v \times C \times H \times W}$, and TI datasets as $[u_1...u_{L_v}] \ in \mathbb{R}^{L_u \times C \times H \times W}$. Future-frame prediction framework zxVAD contains a memory-augmented generator $\mathcal{G}(\cdot)$ with weights $\theta_{\mathcal{G}}$ and memory module $\mathcal{M}$, and a discriminator $\mathcal{D}(\cdot)$ with weights $\theta_{\mathcal{D}}$. The memory module $\mathcal{M} \in \mathbb{R}^{K \times Q}$ is a matrix with $m_i \in \mathbb{R}^Q, \forall_i \in [K]$ vectors that learns to register the prototypical normal features during training. $\mathcal{M}$ takes the output vector $z \in \mathbb{R}^Q$ from $\mathcal{G}(\cdot)$'s encoder and outputs $\hat{z} = w\mathcal{M} \in \mathbb{R}^Q$ that is forwarded to $\mathcal{G}(\cdot)$'s decoder. Here, $w \in \mathbb{R}^{1 \times K}$ is termed as a soft addressing vector. Anomaly synthesis module is denoted as $\mathcal{O}$ and contains a CNN denoted as $\mathcal{R}(\cdot)$ with weights $\theta_{\mathcal{R}}$. Normalcy classifier module contains a CNN classifier denoted as $\mathcal{N}(\cdot)$ with weights $\theta_{\mathcal{N}}$. Denote the expectation operator, $l_p$-norm operator and element-wise multiplication by $\mathbb{E}[\cdot], ||\cdot||_p$ and $\odot$.
<h3>2.2 Backbone description</h3>
Optimizr $\mathcal{G}(\cdot)$ with mean square error loss $\mathcal{L}_{MSE} = ||\hat{v}_{T + 1} - v_{T + 1}||^2_2$, structure similarity loss $\mathcal{L}_{SSM} = 1 - \mathrm{SSIM}(\hat{v}_{T + 1}, v_{T + 1})$, where SSIM M represents the structural similarity index measure and Gradient loss $\mathcal{L}_{GD}$. Apply a hard-shrinkage on $\mathcal{M}$'s memory addressing vectors $w_i$ using ReLU with a shrinkage factor $\lambda$ as 0.0005. Next, normalize each element $\hat{w_i} \leftarrow \hat{w}_i/||\hat{w}||_1 \forall_i$ and get $\hat{z} = \hat{w}\mathcal{M}$. Also apply a sparsity regularizer on $\hat{w}$ by minimizing its entropy as $\mathcal{L}_{MEM} = \sum_{i = 1}^N -\hat{w}_i\log(\hat{w}_i)$. $\mathcal{L}_{BB} = \mathcal{L}_{REC} + \alpha_{MEM}\mathcal{L}_{MEM}$, where $\mathcal{L}_{REC} = \mathcal{L}_{MSE} + \mathcal{L}_{SSM} + \mathcal{L}_{GD}, \alpha_{MEM} = 0.0025$.
<h3>2.3 Pseudo-anomaly synthesis via untrained CNN</h3>
Given an input frame $x \in \mathcal{R}^{C \times H \times W}$, denote the output of a CNN $\mathcal{R}(\cdot)$ as $G \in \mathbb{R}^{d \times h \times w}$. Employ SCDA to perform channel-wise summation on $G$ to obtain an attention map $A \in \mathbb{R}^{h \times w}$. Set $M_{(i, j)} = 1$ if $A_{(i, j)} > \tau$ or 0 otherwise. Here, ($i, j$) represents position in $h \times w$ locations. Set $\tau = 0.1$. $M_{(i, j)} = 1$ indicates foreground objects. Finally, $M$ is resized from $h \times w$ to $H \times W$. The object is finally localized as $M_x = M \odot x$. To create pseudo-abnormal frame $\tilde{v}$, combine $M_x$ and one of the input frames to $\mathcal{G}(\cdot)$ by pasting $M_x$ on $v_t$ at random location $r_z$ with random size $r_x \times r_y$.
<h3>2.4 Learning normality w.r.t abnormality</h3>
Normalcy Classifier Module is optimized by the four loss functions. Normalcy loss and attention affirmation loss focus on the difference between normal and abnormal frames, whereas relative normalcy loss and relative attention affirmation loss focus on how relatively different are normal frames from abnormal frames. The data distribution of normal and pseudo-abnormal frames are denoted as $p$ and $k$.
- Normalcy loss: given the predicted future-frame $\tilde{v}$ and pseudo-abnormal frame $\tilde{v}$: $\mathcal{L}_N = \frac{1}{2}\mathbb{E}_{\tilde{v} \sim p}{[(\mathcal{N}(\hat{v}) - 1)^2] + \frac{1}{2}\mathbb{E}_{\tilde{v} \sim k}[(\mathcal{N}(\tilde{v}))^2]}$.
- Relative normalcy loss: $\mathcal{L}_{RN} = \frac{1}{2}\mathbb{E}_{\tilde{v} \sim p}[(\mathcal{N}(\tilde{v}) - \mathbb{E}_{\tilde{v} \sim k}[\mathcal{N}(\tilde{v})] - 1)^2] + \frac{1}{2}\mathbb{E}_{\tilde{v} \sim k}[(\mathcal{N}(\tilde{v}) - \mathbb{E}_{\tilde{v} \sim p}[\mathcal{N}(\tilde{v})] - 1)^2]$.
- Attention affirmation loss: First initialize a tensor $\tilde{M}$ with zeros. Next, update this tensor by pasting $M$ after resizing to $r_x \times r_y$ at location $r_z$. Extract feature maps from the last convolutional layer $\mathcal{N}(\cdot)$ and apply SCDA to obtain attention maps $\mathcal{A}(\hat{v})$ and $\mathcal{A}(\tilde{v})$ for normal and abnormal frames. $\mathcal{A}(\cdot)$ denotes the operation to extract attention maps from $\mathcal{N}(\cdot)$. $\mathcal{L}_{AA} = \frac{1}{2}(\mathbb{1} - \mathcal{A}(\hat{v}))^2 + \frac{1}{2}(\tilde{M} - \mathcal{A}(\tilde{v}))^2$.
- Relative attention affirmation loss: create two attention map pairs: (Pair-1) $\mathcal{A}(\hat{v})$ and $\mathcal{A}(g(\hat{v}))$ and (Pair-2) $\mathcal{A}(\hat{v})$ and $\mathcal{A}(\tilde{v})$. $g(\cdot)$ denotes a series of transformations applied to $\hat{v}$ using package Kornia. $\mathcal{L}_{RAA}$ is designed using ArcFace loss enforcing margin $m$: $L_{RAA} = \frac{-1}{N}\sum_{i = 0}^{N - 1}\log(\frac{e^{s(\cos(\omega_{y_i} + m))}}{e^{s(\cos(\omega_{y_i} + m))} + \sum_{j = 0, j \neq y_i}e^{scos(\Omega_j)}})$, where label $y_i$ is 1 for normal frame $\hat{v}$ and augmented frame $g(\hat{v})$ and 0 for pseudo-abnormal frame $\tilde{v}$. Transform $\mathcal{A}(x)$ with $\psi_{y_i} = ||W_{y_i}|| ||vec(\mathcal{A}(x))||\cos(\omega_{y_i})$ (with $\omega_{y_i} \in [0, \pi]$) as the angle between $W_{y_i}$ and $vec(\mathcal{A}(x)))$. $||W_{y_i}||$ and ||$vec(\mathcal{A}(x))$|| are normalized to 1 which leads to $\psi_{y_i} = \cos(\omega_{y_i})$. Set scaling factor $s = 64$ and margin $m = 28.6$ degrees.
- Final learning objectives: $\mathcal{L}_{\mathcal{G}} = \mathcal{L}_{BB} + \alpha_\mathcal{D}\mathbb{E}_{\hat{v} \sim p}[\frac{1}{2}(\mathcal{D}(\hat{v}) - 1)^2] + \alpha_\mathcal{N}\mathbb{E}_{\hat{v} \sim p}[\frac{1}{2}(\mathcal{N}(\hat{v}) - 1)^2], \mathcal{L}_\mathcal{D} = \mathbb{E}_{\hat{v} \sim p}[\frac{1}{2}(\mathcal{D}(\hat{v}))^2] + \mathbb{E}_{\hat{v} \sim p}[\frac{1}{2}(\mathcal{D}(\hat{v}) - 1)^2], \mathcal{L}_\mathcal{N} = \alpha_n\mathcal{L}_N + \alpha_{rn}\mathcal{L}_{RN} + \alpha_{aa}\mathcal{L}_{AA} + \alpha_{raa}\mathcal{L}_{RAA}$. Set $\alpha_\mathcal{D} = 0.05, \alpha_\mathcal{N} = 0.5, \alpha_n = 1, \alpha_{rn} = 0.01, \alpha_{aa} = 1, \alpha_{raa} = 1$.
<h3>3. Datasets</h3>
ShanghaiTech, UCF-Crime, Ped1/2, Avenue, HMDB51, UCF101 and 20BN-JESTER.
<h2>4. Metrics</h2>
AUC.