<h2>1. Abstract</h2>
Propose spatial rotation transformation (SRT) and temporal mixing transformation (TMT) to generate irregular patch cuboids within normal frame cuboids in order to enhance the learning of normal features. Additionally, the proposed patch transformation is used only during training phase, allowing model to detect abnormal frames at fast speed.
<h2>2. Introduction</h2>
The purpose of SRT is to generate an abnormal appearance and encourage model to learn spatially invariant features of normal events. TMT which is shuffling the selected patch cube is the temporal axis to create abnormal motion, is intended to enhance learning temporally invariant features of normal events.
<h2>3. Related work</h2>
<h3>3.1 AE-based approach</h3>
Two-path AE, where two encoders were used to model appearance and motion features.
<h3>3.2 Transformation-based approach</h3>
Generate abnormal frames from normal frames by cropping an object detected with a semantic segmentation model and placing it in another region in the frame to generate an abnormal appearance.
<h2>4. Proposed approach</h2>
<h3>4.1 Overall architecture</h3>
During the training phase, first load $n$ adjacent frames to make a frame cuboid. After that, apply patch anomaly generation to the frame cuboid which is forwarded to the AE. AE extracts spatial and temporal patterns of the input and generates a future frame. During inference, the patch anomaly generation is not employed. A raw frame cuboid is fed as an input to AE. the difference between the output of AE and ground truth frame is used as a score to judge normality.
<h3>4.2 Patch anomaly generation phase</h3>
The patch anomaly generation phase takes place before feeding the frames to the generator. Load $n$ successive frames $F_t, F_{t + 1},...,F_{t + n - 1}$, resize each to 240 $\times$ 360 and concatenate them on the temporal axis to form a 4D cuboid $C_f \in \mathbb{R}^{C \times n \times 240 \times 360}$. After that, select a patch cuboid $C_p \in \mathbb{R}^{C \times n \times 60 \times 60}$ from a random location within $C_f$ to apply transformation. Since anomalies usually occur in foregrounds, exclude a margin of 12.5 percent in length from the top and bottom of width of $C_f$ from the selection area. Then, apply SRT or TMT to $C_p$ to form a transformed patch cuboid $C'_p$. Only one of the two is applied randomly for every input. For SRT, each patch is rotated in a random direction between 0$^{\circ}$, 90$^{\circ}$, 180$^{\circ}$ and 270$^{\circ}$, By forwarding these transformed frame cuboids $C'_f (F'_t, F'_{t + 1},...,F'_{t + n - 1})$ to the frame generator, the network is encouraged to focus on abnormal region and recognize spatial features of normal appearances. $SRT(F_i) = R(F_{i_{(x, i) \in [(x, x + W_p), (y, y + H_p)]}}, \delta_i)$, where $R$ represents the rotation function for a patch within the pixel range of $[x, x + W_p]$ in the width axis and $[y, y + H_p]$ in the height axis of input frame $F_i$. $\delta_i$ denotes the randomly set direction for the $i^{th}$ frame, where $i$ is the index of the input frame in $[0, n - 1]$. $W_p$ and $H_p$ represent fixed with and height of patch. The final $C'_f$ is generated by concatenating transformed $F'_i$ in the temporal axis. TMT involves shuffling the sequence of patch cuboid $C_p$ in the temporal axis with the intention of generating abnormal movement. $TMT(F_i) = T(F_i, F_{\xi_{i_{(x, y) \in [(x, x + W_p), (y, y + H_p)]}}})$, where $T$ denotes a function that copies a patch located in pixel range of $[x, x + W_p]$ in the width axis and $[y, y + H_p]$ in the height axis of input frame $F_{\xi_i}$ and pastes it to the $i^{th}$ frame. $\xi$ represents the shuffled sequence of $n$ patches. Same as SRT, the final $C'_f$ is the stack of transformed $F_i$.
<h3>4.3 AE architecture</h3>
The encoder consists of a stack of three-layer blocks that reduce the resolution of feature map. Employ 3D convolution to embed the temporal factor learning. Specifically, first block consists of one convolutional layer and one activation layer. The second and last blocks are identical in structure: convolutional, batch norm and activation layers. The kernel size is set to 3 $\times$ 3 $\times$ 3 for all three layers. The decoder also consists of a stack of three-layer blocks and is symmetrical to the encoder except that the convolutional layers are replaced by deconvolutional layers to upscale feature map. In addition, use leakyReLU for encoder and ReLU for decoder.
<h3>4.4 Objective function and normality score</h3>
Use L1 distance and SSIM loss to measure the difference between generated frame $P'_t$ and ground truth frame $P_t$. $L_p(P'_t, P_t) = |P'_t, P_t|, L_f(P'_t, P_t) = 1 - \frac{(2\mu_{P'_t}\mu_{p_t} + c_1)(2\sigma_{P'_tP_t} + c_2)}{(2\mu^2_{P'_t}\mu^2_{P_t} + c_1)(\sigma^2_{P'_t} + \sigma^2_{P_t} + c_2)}$, where $\mu$ and $\sigma^2$ denote the average and variance of each frame, Furthermore, $\sigma_{P'_tP_t}$ represents the covariance. $c_1$ and $c_2$ denote variables to stabilize the division. Exploit a weighted combination of two loss function: $L_{pred}(P'_t, P_t) = \omega_pL_p(P'_t, P_t) + \omega_fL_f(P'_t, P_t)$, where $\omega_p$ and $\omega_f$ are weights controlling contribution of $L_p$ and $L_f$. 
<h2>5. Datasets</h2>
CUHK Avenue, Shanghaitech and UCSD Ped2. 
<h2>6. Metrics</h2>
AUC, ROC and FPS. 