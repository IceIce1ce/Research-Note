<h2>1. Abstract</h2>
Propose URDMU model to learn both the representations of normal data and discriminative features of abnormal data. Introduce GL-MHSA module for the Transformer network to obtain more expressive embeddings for capturing associations in videos. Then, use two memory banks, one additional abnormal memory for tackling hard samples, to store and separate abnormal and normal prototypes and maximize the margins between the two representations. Finally, propose an uncertainty learning scheme to learn the normal data latent space.
<h2>2. Method</h2>
<h3>2.1 Global and local feature learning</h3>
Different from the conventional MHSA, add an extra encoder layer of $V_l = X_{i3d}W_l$ to learn local features with a temporal mask: $T_m(i, j) = -\frac{|i - j|}{e^\tau}$. Then, normalize mask with softmax. While computing $Q, K, V$, obtain global and local feature $X \in \mathbb{R}^{N \times D}$ from MIL and LayerNorm.
<h3>2.2 Dual memory units</h3>
$S = \sigma(\frac{XM^T}{\sqrt{D}}), M_{aug} = SM$, where $M \in \mathbb{R}^{M \times D}$ is memory bank number, $S \in \mathbb{R}^{N \times M}$ is query score. Then the memory augmentation feature generated by a read operation is represented as $M_{aug}$. $S$ indicates whether snippets are similar to memory banks. Apply topK selection along second dim to determine which snippets are most similar to memory banks: $S_{k; ind}, S_{k; sc} = topK(S, K), S_{k, i} = \frac{\sum_{j = 1}^KS_{k; sc}(i, j)}{K}$, where $K <<M, S_{k; ind}$ means indices of proposed K snippets to be stored and $S_{k; sc} \in \mathbb{R}^{N \times K}$ are their query scores. $S_{k} \in \mathbb{R}^{N \times 1}$ indicates highest scores of memory matching. While sending normal video embedding $X^n \in \mathbb{R}^{N \times D}$ into abnormal memory banks, $S^n_{k; a}$ and $M^n_{aug; a}$ are generated by querying and reading operations. Similarly, obtain $S^n_{k; n}, M^n_{aug; n}$ as video embedding goes through normal memory banks. The anomaly scores $S^n_{k; a}$ are constrained to 0 $\in \mathbb{R}^N$ because of the normal input. And normal query $S^n_{k; n}$ should be 1 $\in \mathbb{R}^N$. Likewise, when the abnormal video embedding input to abnormal memory banks, obtain $S^a_{k; a}, M^a_{aug; a}$. Also obtain $S^a_{k; n}, M^a_{aug; n}$ from normal memory banks. Same MIL, there is at least one element equals 1 in $S^a_{k; a}$ and $S^a_{k; n}$. Dual memory loss: $L_{dm} = BCE(S^n_{k; n}, y^n_n) + BCE(S^n_{k; a}, y^n_a) + BCE(S^a_{k; n;k}, y^a_n) + BCE(S^a_{k;a;k}, y^a_a)$, where $y^n_n = 1 \in \mathbb{R}^N, y^n_a = 0 \in \mathbb{R}^N$. $S^a_{k;n;n}, S^a_{k;a;k} \in \mathbb{R}$ are means of $S^a_{k;n}, S^a_{k;a}$ topK result along first dim. The label $y^a_n, y^a_a$ are 1. Separate the abnormal and normal feature embedding by triplet loss: $L_{trip} = Triplet(f_a, f_p, f_n)$, where $f_a = topK(S^n_{k;n};X^n), f_p = topK(S^a_{k;n};X^a), f_n = topK(S^a_{k;a};X^a)$. 
<h3>2.3 Normal data uncertainty learning</h3>
The magnitude separability of augmentation features between abnormal and normal is defined: $d(a, n) = ||m^a||_2 - ||m^n||_2$. Propose to use the Gaussian distribution to constraint the latent normal representation $z^n$. Use reparameterization to tackle latent with noise. The DUL features $z^n$ is generated by random noise: $\epsilon \sim \mathcal{N}(0, 1): z^n_i = \mu^n_i + \sigma^n_i\epsilon$. However, the sample $z$ is impressionable to $\sigma$ when $\sigma$ is large. KL regularization term is necessary: $L_{kl} = -\frac{1}{2D}\sum_{i = 1}^D(1 + \log(\sigma^n_i)^2 - (\mu^n_i)^2 - (\sigma^n_i)^2)$. The anomaly features are also fed to the mean-encoder to get the embedding $\mu^a$ in same space. Use magnitude distance loss to separate them in the latent normal space: $L_{dis} = max(0, d - (||\mu^a_k||^2_2 - ||z^n_k||^2_2))$, where $\mu^a_k$ are average features of proposed snippets from $M_{aug}$. $z^n_k$ is obtained from $S^n_{k;n}$ and $M_{aug}$. Finally, fuse DUL features with X and feed it to classifier.
<h3>2.4 Network training and testing</h3>
- Training: $L = L_{cls} + \lambda_1L_{dm} + \lambda_2L_{trip} + \lambda_3L_{kl} + \lambda_4L_{dis}$.
- Testing: in DUL module, only use mean-encoder network to obtain feature embeddings.
<h2>3. Datasets</h2>
UCF-Crime and XD-Violence.
<h2>4. Metrics</h2>
AUC and AP.
<h2>5. Code</h2>
https://github.com/henrryzh1/UR-DMU.