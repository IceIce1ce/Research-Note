<h2>1. Abstract</h2>
Gold-YOLO boosts the multi-scale feature fusion capabilities and achives an ideal balance between latency and accuracy. Additionally, implement MAE-style pretraining in YOLO-series for first time, allowing YOLO-series models could be to benefit from unsupervised pretraining.
<h2>2. Method</h2>
The process gather and distribute correspond to three modules: Feature Alignment Module (FAM), Information Fusion Module (IFM), and Information Injection Module (Inject). The gather process involves two steps. Firstly, the FAM collects and aligns features from various levels. Secondly, IFM fuses the aligned features to generate global information. The inject module distribute this information across each level and injects it using simple attention operations. To enhance the model’s ability to detect objects of varying sizes, developed two branches: lowstage gather-and-distribute branch (Low-GD) and high-stage gather-and-distribute branch (High-GD). Neck's input comprises feature maps $B2, B3, B4, B5$ extracted by the backbone, where $B_i \in \mathbb{R}^{N \times C_{B_i} \times R_{B_i}}$. Moreover, the dimensions of $R_{B2}, R_{B3}, R_{B4}$ and $R_{B5}$ are $R, \frac{1}{2}R, \frac{1}{4}R$ and $\frac{1}{8}R$.
<h3>2.1 Low-stage gather-and-distribute branch</h3>
- Low-stage feature alignment module: employ AvgPool to down-sample input features and achieve a unified size. By resizing the features to the smallest feature size of the group ($R_{B4} = \frac{1}{4}R$), obtain $F_{align}$. Choose $R_{B4}$ as the target size of feature alignment.
- Low-stage information fusion module: comprise multi-layer reparameterized convolutional blocks (RepBlock) and a split operation. Specifically, RepBlock takes $F_{align}$ as input and produces $F_{fuse}$. The middle channel is an adjustable value (e.g., 256) to accommodate varying model sizes. The features generated by the RepBlock are subsequently split in the channel dimension into $F_{inj\_P3}$ and $F_{inj\_P4}$, which are then fused with the different level’s feature. $F_{align} = Low_FAM([B2, B3, B4, B5]), F_{fuse} = RepBlock(F_{align}), F_{inj\_P3}, F_{inj\_P4} = Split(F_{fuse})$
- Information injection module: input both local information and global inject information denoted as $F_{local}, F_{inj}$. Use two different Convs with $F_{inj}$ for calculation, resulting in $F_{global\_embed}$ and $F_{act}$. While $F_{local\_embed}$ is calculated with $F_{local}$ using Conv. The fused feature $F_{out}$ is then computed through attention. Employ average pooling or bilinear interpolation to scale $F_{global\_embed}, F_{act}$ according to size of $F_{inj}$, ensuring proper alignment. At the end of each attention fusion, add the RepBlock to further extract and fuse the information.
<h3>2.2 High-stage gather-and-distribute branch</h3>
The High-GD fuses the features ${P3, P4, P5}$ that are generated by Low-GD.
- High-stage feature alignment module: consist of avgpool. When the size of the input feature is ${R_{P3}, R_{P4}, R_{P5}}$, avgpool reduces the feature size to the smallest size within the group of features $(R_{P5} = \frac{1}{8}R)$.
- High-stage information fusion module: comprise the transformer block and a splitting operation which involves a three-step process: (1) $F_{align}$ derived from the High-FAM, are combined using the transformer block to obtain the $F_{fuse}$, (2) $F_{fuse}$ channel is reduced to $sum(C_{P4}, C_{P5})$ via Conv1 $\times$ 1, (3) $F_{fuse}$ is partitioned into $F_{inj\_N4}, F_{int\_N5}$ along the channel dimension through a splitting operation.
- Information injection module: is exactly the same as in Low-GD.
<h3>2.3 Enhanced cross-layer information flow</h3>
Introduced an Inject-LAF module. Designed two LAF models: LAF low-level model and LAF high-level model, which are respectively used for low-level injection (merging features from adjacent two layers) and high-level injection (merging features from adjacent one layer). Two LAF models utilize only three operators: bilinear interpolation, average pooling and $1 \times 1$ convolution.
<h3>2.4 Masked image modeling pre-training</h3>
Adopt MIM Pre-training following the SparK’s methodology.
<h2>3. Datasets</h2>
MS COCO 2017.
<h2>4. Metrics</h2>
AP$^{val}$, AP$^{val}_{50}$, FPS, Latency, Params FLOPs, AP-small, AP-medium, AP-large, Bbox mAP, Bbox mAP:50, Segm mAP, Segm mAP:50, mIoU, mAcc and aAcc.
<h2>5. Code</h2>
https://gitee.com/mindspore/models/tree/master/research/cv/Gold_YOLO.