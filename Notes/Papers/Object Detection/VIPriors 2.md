<h2>1. Abstract</h2>
Second edition, prohibit the use of pre-trained checkpoints and other transfer learning techniques.
<h2>2. Introduction</h2>
Top competitors heavily rely on model ensembling and data augmentation.
<h2>3. Challeges</h2>
<h3>3.1 Classification</h3>
<h4>3.1.1 First place</h4>
Use a mixture of experts models, which learns multiple different neural architectures in  parallel, while sharing some initial backbone layers. The embeddings of all experts are fused, after which a final layer makes the final prediction. During training, each expert has a separate classifier, which optimizes against distilled targets generated by a single separate teacher model. Diversity between experts is stimulated by optimizing the negative KL-divergence between the average output of the experts and the current experts output. 
<h4>3.1.2 Second place</h4>
- Xidian university team uses model ensembling with a ResNet, a TResNet, a Rexnet and an Inception-ResNet. Combine data augmentation methods and label smoothing with dynamic semantic scale balance loss (DSB).
- Hikvision team uses a representation trained with constrastive regularization, adding in Mean Teacher loss and Symmetric Cross Entropy loss. Additionally, use model ensembling and aggressive data augmentation.
- Nanyang Technological university team first uses self-supervised learning to train a representation, then uses the weights of the learned network to initialize a teacher and a student model in a distillation framework. The distillation network phase is trained with RandAugment and AutoAugment, label smoothing, random erasing. For self-supervised learning, propose a novel method called Iterative Pertition-based Invariant Risk Minimization (IP-IRM) which is grounded in group equivariance to disentangle the difference semantic concepts of a representation.
<h4>3.1.3 Conclusion</h4>
heavy use of network ensembles and data augmentation. ResNeSt and AutoAugment are popular methods.
<h3>3.2 Object Detection</h3>
<h4>3.2.1 First places</h4>
- Lu et al. employ a multi-scale bagging method with various YOLO detectors. First, they split the given dataset into 4 independent train and validation sets. Afterwards, they utilize data augmentation methods such as mosaic, mix-up and random color-jittering. Lastly, WBF is used to refine predicted boxes from different detectors.
- Zhang et al. use Cascade RCNN with ResNet-50 backbone with DCN. First, they start with self-supervised learning method MoCo to pretrain the model. Afterwards, they train the model for 24 epochs with multi-scale image sizes. Instead of NMS, they use Soft-NMS and category-specific IoU thresholds. In addition, box ensemble of Cascade RCNN and Double-Head (DH Faster RCNN) is applied.
<h4>3.2.2 Second places</h4>
- Niu et al. train swin transformer with 4x4 patch inputs. Swin-T transformer architecture with 96 channels is followed by FPN. Train the detector with 6 different image sizes with a multi-scale manner for 50 epochs. Train Deformable DETR Transformer, yet Swin Transformer outperforms on DelftBikes dataset by 2%. Applying Soft-NMS, pseudo labeling and dividing the part classes in 2 parts increase both Deformable DETR and Swin Transformers results.
- Luo et al. use Cascade RCNN coupled with DCN and Global Context Modeling Network (GCNet). First, create synthetic dataset with 10K images for contrastive self-supervised learning by using SimSiam method. In addition, utilize multi-scale training and testing, data augmentation and Soft-NMS.
<h4>3.2.3 Jury prize</h4>
just filling the bounding box location of first 10 classes as [NaN, NaN, NaN, NaN]. When giving NaN locations for every classes on validation set, the score becomes 97% --> bug in COCO API.
<h3>3.3 Instance Segmentation</h3>
<h4>3.3.1 First place & jury prize</h4>
Based on HTC detector and CBSwin-T backbone with CBFPN using group normalization. During training, the multi-scale sampling mode is used. Inference is performed on a single fixed scale. Data augmentation: instances are cropped based on their segmentation masks and are copied onto different images, while maintaining class balance. The locations where the instances are placed are constrained to be realistic. RandAugment and GridMask data augmentation methods are employed.
<h4>3.3.2 Second place</h4>
Dataset is first expanded by generating ten augmented versions for each original image. Offiline augmentations include color transformations (random brightness, color jitter, saturation and sharpen), quality transformations (random blur, noise, pixel shufflin and pixelization), filter transformations from the PIL.ImageFilter library and hue transformations. Random flip, random cropping, bbox-jitter and grid-mask and performed during online augmentation. The segmentation model is based on HTC using a ResNet-101 with switchable atrous convolutions and group normalization. 
<h4>3.3.3 Thrid place</h4>
Based on Cascade R-CNN. The swin transformer is used as the feature extractor. Data augmentation in training: random flips, scaling and cropping. At test time, multi-scale fusion is performed to improve performance.
<h3>3.4 Action Recognition</h3>
<h4>3.4.1 First places & jury prize</h4>
- Dave et al. use both convolutional R3D and I3D and attention based MViT models. For the convolutional ones, the self-supervised training process TCLR is applied first. Then, the resulting models are finetuned using RGB and optical flow frames. On the other hand, the transformer model MViT is trained directly on Kinetics400ViPriors using only RGB frames.
- Wu et al. consider that the visual tempo (or dynamics) of an action plays a vital role. To capture this information, propose to fuse three TPN architectures. Each of the TPN modules is complemented by a Slowonly network, which is the slow path of the Slowfast network. Additionally, mixup and cutmix data augmentation techniques are applied during training.
<h4>3.4.2 Second place</h4>
A combination of some of the best performing methods for Action Recognition: Swin Transformer, TPN, X3D, R2+1D, Slowfast and Timesformer.
<h3>3.5 Re-identification</h3>
<h4>3.5.1 First place</h4>
Three components: pre-processing, strong backbones and post-processing. On pre-processing, addressing noisy labels. Apply an online difficult sample mining algorithm in order to filter out the hard occluded annotations. The occluded annotations were divided into partial occlusions and full occlusions. Apply data augmentation on the former to increase their proportion in the training set. Apply Random Erasing and Local Grayscale Transform (LGT) as data augmentation methods. LGT avoided color similarities in the jersey. Standard augmentation: affine transformations, pixel padding, random flip. Finally, oversampled IDs with less than 20 images in gallery to balance the training set. Adopted the re-identification baseline together with an ensemble of ResNet, ResNetSt, SE-ResNetXt: a total of 24 models where used in the ensemble, including ResNet-101, ResNet-151, ResNet-200, ResNeSt-101, ResNeSt-152, ResNeSt-200, SE-ResNeX-t101, SE-ResNeXt-152, SE-ResNeXt-200. Apply generalized mean pooling instead of GAP. Finally, use a combination of triplet loss and circle loss. For post-processing, apply common techniques for re-id tasks: augmentation test, re-ranking and query expansion.
<h4>3.5.2 Second place & jury prize</h4>
Propose a post-processing strategy named video temporal relationship mining: the first frame of the video is used to retrieve the second frame. Then, the second frame is used to retrieve the next frame and so on. Baseline model was MGN (multiple granularity network: a global branch for global feature representations and local branches for horizontal splits). Train an ensemble of models: ResNet-50 with IBN, while Batch Normalization was replaced by SyncBN with cross-entropy and triple loss. Other choices came from BoT including data augmentation methods: random erase, random horizontal flipping and padding. Post-processing: re-ranking and 6x Schedule.
<h4>3.5.3 Thrid place</h4>
Propose a stronger baseline: a slight modification of strong baseline, providing tiny overhead but faster convergence rate and recognition performance. See BNNeck as a standardization procedure: stronger baseline allows to improve optimization conflicts between cosine metric space and euclidean metric space. Data augmentation: horizontal flip, random erasing, color jitter, AutoAugmentation. Post-processing: query expansion and re-ranking.